{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Preprocessing Datasets\n",
    "\n",
    "[![Static Badge](https://img.shields.io/badge/Back_to_README.md-red?style=for-the-badge&logo=github&labelColor=black)](https://github.com/izzad2413/sustainable_ota)\n",
    "\n",
    "### Table of Contents<a id=\"main\"></a>\n",
    "\n",
    "- [2.1 Duplicates & Error Data](#1)\n",
    "- [2.2 Change NaN Value](#2)\n",
    "- 2.3 Features Cleaning\n",
    "  - [2.3.1 About](#3)\n",
    "    - name & description\n",
    "    - address\n",
    "    - coordinate\n",
    "  - [2.3.2 Room & Price](#4)\n",
    "    - prices_range\n",
    "  - [2.3.3 Review](#5)\n",
    "    - review_titles & reviews_overall_score\n",
    "    - score_status\n",
    "    - count_qna\n",
    "    - count_reviewer_by_cat & count_reviewer_by_scores\n",
    "    - count_reviewer_by_lan\n",
    "  - [2.3.4 Host](#6)\n",
    "    - host_count_reviews\n",
    "  - [2.3.5 Surroundings](#7)\n",
    "    - landmarks, topattractions, publictransport, closestairports & restaurantscafes\n",
    "  - [2.3.6 Facilities](#8)\n",
    "  - [2.3.7 Sustainability](#9)\n",
    "    - sustainable_level\n",
    "    - sustainable impact category\n",
    "- [2.4 Finalised Dataset](#10)\n",
    "  - 2.4.1 Dropping the original features\n",
    "  - 2.4.2 Move the target feature to the end\n",
    "  - 2.4.3 Final check for null values\n",
    "  - 2.4.4 Saving the processed data\n",
    "- [2.5 Process Dataset for Modeling](#11)\n",
    "  - 2.5.1 Encoding categorical variables\n",
    "  - 2.5.2 Handling outliers\n",
    "  - 2.5.3 Saving the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy.stats import mstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './../data/interim/combined_data_v4.csv' # dataset directory\n",
    "df = pd.read_csv(data_dir) # read the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Duplicates & Error Data<a id=\"1\"></a> [![Static Badge](https://img.shields.io/badge/Back_to_Table_of_Contents-orange?style=flat&logo=jupyter&logoColor=white)](#main)\n",
    "\n",
    "To scan any samples that are duplicated and may contain errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Drop\n",
      "Dataset size 17866\n",
      "There are 1997 duplicated data detected\n",
      "\n",
      "Data Checking\n",
      "Total samples that meet the condition 1: 1\n",
      "Total samples that meet the condition 2: 1\n",
      "\n",
      "After Drop\n",
      "Dataset size 15265\n",
      "There are 0 duplicated data detected\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Drop\")\n",
    "print(f'Dataset size {len(df)}')\n",
    "print(f'There are {df.duplicated().sum()} duplicated data detected\\n')\n",
    "\n",
    "# keep the first occurence, delete the others\n",
    "# drop duplicates in a specific column, keeping the first occurrence\n",
    "df.drop_duplicates(subset=['name'], keep='first', inplace=True)\n",
    "\n",
    "# checking any error (null values) on sample\n",
    "print(\"Data Checking\")\n",
    "condition_1 = df[(df['preferred_partner'] == 0) &\n",
    "                 (df['state'].notnull()) &\n",
    "                 (df['name'].isnull()) &\n",
    "                 (df['address'].isnull())]\n",
    "\n",
    "condition_2 = df[(df['name'] == 'testing genting ion delemen')]\n",
    "\n",
    "condition_1_total_samples = len(condition_1)\n",
    "condition_2_total_samples = len(condition_2)\n",
    "\n",
    "# check the samples\n",
    "print(f'Total samples that meet the condition 1: {condition_1_total_samples}')\n",
    "print(f'Total samples that meet the condition 2: {condition_2_total_samples}\\n')\n",
    "\n",
    "# droppin the samples\n",
    "condition_1_indices_to_drop = condition_1.index\n",
    "condition_2_indices_to_drop = condition_2.index\n",
    "df.drop(condition_1_indices_to_drop, inplace=True)\n",
    "df.drop(condition_2_indices_to_drop, inplace=True)\n",
    "\n",
    "# check if there is more duplicate values\n",
    "print(\"After Drop\")\n",
    "print(f'Dataset size {len(df)}')\n",
    "print(f'There are {df.duplicated().sum()} duplicated data detected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Change NaN Value<a id=\"2\"></a> [![Static Badge](https://img.shields.io/badge/Back_to_Table_of_Contents-orange?style=flat&logo=jupyter&logoColor=white)](#main)\n",
    "\n",
    "Replacing the following features that have NaN values to 0\n",
    "\n",
    "- star_rating\n",
    "- quality_rating\n",
    "- overall_reviews\n",
    "- count_reviews\n",
    "- host_score_review\n",
    "- count_uploaded_pics\n",
    "- count_room_types\n",
    "- count_landmarks\n",
    "- count_top_attractions\n",
    "- count_publictransport\n",
    "- count_closestairports\n",
    "- count_restaurantscafes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.star_rating = df.star_rating.fillna(0)\n",
    "df.quality_rating = df.quality_rating.fillna(0)\n",
    "df.overall_reviews = df.overall_reviews.fillna(0)\n",
    "df.count_reviews = df.count_reviews.fillna(0)\n",
    "df.host_score_review = df.host_score_review.fillna(0)\n",
    "df.count_uploaded_pics = df.count_uploaded_pics.fillna(0)\n",
    "df.count_room_types = df.count_room_types.fillna(1)\n",
    "df.count_landmarks = df.count_landmarks.fillna(0)\n",
    "df.count_topattractions = df.count_topattractions.fillna(0)\n",
    "df.count_publictransport = df.count_publictransport.fillna(0)\n",
    "df.count_closestairports = df.count_closestairports.fillna(0)\n",
    "df.count_restaurantscafes = df.count_restaurantscafes.fillna(0)\n",
    "df.rename(columns={'sustainable_level': 'travel_sustainable_level'}, inplace=True)\n",
    "df['travel_sustainable_level'] = df['travel_sustainable_level'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Cleaning\n",
    "\n",
    "#### 2.3.1 About<a id=\"3\"></a> [![Static Badge](https://img.shields.io/badge/Back_to_Table_of_Contents-orange?style=flat&logo=jupyter&logoColor=white)](#main)\n",
    "\n",
    "- name & description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword on sustainable tourism\n",
    "\n",
    "def check_eco_mention(description):\n",
    "  sustainable_terms = [\n",
    "    'accessible',\n",
    "    'certification',\n",
    "    'climate neutral',\n",
    "    'collaboration',\n",
    "    'community consent',\n",
    "    'conservation',\n",
    "    'continuous improvement',\n",
    "    'cultural',\n",
    "    'environmentally sustainable',\n",
    "    'equitable',\n",
    "    'fair trade',\n",
    "    'free roaming wildlife',\n",
    "    'ghg emissions',\n",
    "    'greenhouse gas',\n",
    "    'gstc-certified',\n",
    "    'gstc-i accredited',\n",
    "    'gstc-i recognized',\n",
    "    'habitat',\n",
    "    'local',\n",
    "    'low-impact transportation',\n",
    "    'management',\n",
    "    'natural heritage',\n",
    "    'responsible consumption',\n",
    "    'restoration',\n",
    "    'sensitivity',\n",
    "    'social impact assessment',\n",
    "    'sustainability',\n",
    "    'sustainable destination strategy',\n",
    "    'sustainable investment',\n",
    "    'sustainable materials',\n",
    "    'sustainable practices',\n",
    "    'sustainable tourism',\n",
    "    'threatened species',\n",
    "    'tourism assets',\n",
    "    'transparent',\n",
    "    'water stewardship',\n",
    "    'wildlife',\n",
    "    'wildlife interaction',\n",
    "    'ecofriendly',\n",
    "    'eco friendly',\n",
    "    'eco-friendly',\n",
    "    'eco'\n",
    "] # source: https://www.gstcouncil.org/gstc-criteria/glossary/\n",
    "  \n",
    "  # Check if the value is NaN\n",
    "  if pd.isna(description):\n",
    "    return 0\n",
    "\n",
    "  # Convert the description to lowercase\n",
    "  description_lower = str(description).lower()\n",
    "\n",
    "  # Check if any of the specified words are mentioned\n",
    "  eco_mentioned = any(keyword in description_lower for keyword in sustainable_terms)\n",
    "\n",
    "  # Return 1 if mentioned, else 0\n",
    "  return 1 if eco_mentioned else 0\n",
    "\n",
    "df['eco_mentioned_name'] = df['name'].apply(check_eco_mention)\n",
    "df['eco_mentioned_description'] = df['description'].apply(check_eco_mention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract postcode from address feature\n",
    "def extract_postcode(text):\n",
    "  if pd.isna(text):\n",
    "    return None\n",
    "\n",
    "  text = text.split(',')[-2].strip()\n",
    "  postcode = re.findall(r'\\d+\\.*\\d*', text)\n",
    "\n",
    "  if postcode:\n",
    "    postcode = postcode[0]\n",
    "    return int(postcode)\n",
    "  else:\n",
    "    return None\n",
    "\n",
    "def add_city_from_postcode(dataframe, csv_file_path):\n",
    "    # Read the CSV file containing postcode and city columns\n",
    "    postcode_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Dictionary mapping postcodes to cities\n",
    "    postcode_to_city = dict(zip(postcode_df['postcode'], postcode_df['city']))\n",
    "\n",
    "    # Create a new column 'city' in the original dataframe\n",
    "    dataframe['city'] = dataframe['extracted_postcode'].apply(lambda x: postcode_to_city.get(x) if pd.notnull(x) else None)\n",
    "\n",
    "    return dataframe\n",
    "  \n",
    "postcode_city = './../references/data/malaysia_all-postcode_multi-sources.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['extracted_postcode'] = df.address.apply(extract_postcode)\n",
    "df = add_city_from_postcode(df, postcode_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state      \n",
      "melaka         15\n",
      "kualalumpur    14\n",
      "Name: count, dtype: int64\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'city' column is null\n",
    "null_postcode_filter = df[df['extracted_postcode'].isnull()]\n",
    "\n",
    "# Retrieve the addresses of the filtered rows\n",
    "filtered_data = null_postcode_filter[['state']]\n",
    "\n",
    "# Print the filtered addresses\n",
    "print(filtered_data.value_counts())\n",
    "print(len(filtered_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the null value in city according to state\n",
    "df.loc[(df['state'] == 'kualalumpur') & (df['city'].isnull()), 'city'] = 'bukit bintang'\n",
    "df.loc[(df['state'] == 'melaka') & (df['city'].isnull()), 'city'] = 'banda hilir, melaka raya'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coordinates(df):\n",
    "    # Extract the 'coordinate' column\n",
    "    coordinates = df['coordinate'].str.split(',', expand=True)\n",
    "\n",
    "    # Create new columns 'lat' and 'long'\n",
    "    df['prop_lat'] = coordinates[0].astype(float)\n",
    "    df['prop_long'] = coordinates[1].astype(float)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = extract_coordinates(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Room & Price<a id=\"4\"></a> [![Static Badge](https://img.shields.io/badge/Back_to_Table_of_Contents-orange?style=flat&logo=jupyter&logoColor=white)](#main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ave_price(row):\n",
    "    if pd.isna(row):\n",
    "        return 0  # Return 0 for NaN values\n",
    "    elif isinstance(row, int):\n",
    "        return row  # Return the integer as it is\n",
    "    else:\n",
    "        # Replace commas with empty strings and split by space to get individual numbers\n",
    "        numbers = re.sub(r',', '', row).split()\n",
    "        numbers = [int(num) for num in numbers]  # Convert strings to integers\n",
    "        numbers.sort()  # Sort the numbers in ascending order\n",
    "        median = np.median(numbers)  # Calculate median\n",
    "        return median\n",
    "\n",
    "df['average_price'] = df['prices_range'].apply(cal_ave_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_by_state_and_star_rating = df.groupby(['state', 'star_rating'])['average_price'].median()\n",
    "\n",
    "# Perform data imputation for 0 value\n",
    "df['average_price'] = df.apply(\n",
    "    lambda row: median_by_state_and_star_rating[(row['state'], row['star_rating'])] if row['average_price'] == 0 else row['average_price'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove extreme values\n",
    "price_outliers = df[(df['average_price'] > 22000)]\n",
    "\n",
    "# dropping the samples\n",
    "price_outliers_to_drop = price_outliers.index\n",
    "df.drop(price_outliers_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Review<a id=\"5\"></a> [![Static Badge](https://img.shields.io/badge/Back_to_Table_of_Contents-orange?style=flat&logo=jupyter&logoColor=white)](#main)\n",
    "\n",
    "- review_titles & reviews_overall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_titles_review_scores(df):\n",
    "    # Create a dictionary to store extracted values\n",
    "    extracted_values = {}\n",
    "\n",
    "    # Iterate over rows\n",
    "    for index, row in df.iterrows():\n",
    "        titles = row['review_titles']\n",
    "        reviews = row['review_overall_scores']\n",
    "\n",
    "        # Replace NaN with 0 in 'review_titles' and 'review_overall_scores'\n",
    "        titles = titles if pd.notna(titles) else '0'\n",
    "        reviews = reviews if pd.notna(reviews) else '0'\n",
    "\n",
    "        # Split titles and reviews\n",
    "        title_list = titles.split(', ')\n",
    "        review_list = list(map(float, reviews.split(', ')))\n",
    "\n",
    "        # Update the dictionary with extracted values\n",
    "        for title, review in zip(title_list, review_list):\n",
    "            # Convert title to lowercase and add \"review_\" prefix\n",
    "            title_lower = f\"review_{title.lower()}\"\n",
    "\n",
    "            if title_lower not in extracted_values:\n",
    "                extracted_values[title_lower] = [0] * len(df)\n",
    "\n",
    "            # Ensure the list has enough elements to accommodate the current index\n",
    "            while len(extracted_values[title_lower]) <= index:\n",
    "                extracted_values[title_lower].append(0)\n",
    "\n",
    "            extracted_values[title_lower][index] = review\n",
    "\n",
    "    # Add the extracted values to the DataFrame\n",
    "    for title, values in extracted_values.items():\n",
    "        # Ensure the length of the values matches the length of the DataFrame\n",
    "        values = values[:len(df)]\n",
    "        df[title] = values\n",
    "\n",
    "    return df\n",
    "\n",
    "df = extract_titles_review_scores(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- score_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_status\n",
    "# to extract 'Low' or 'High' scores\n",
    "def extract_scores(text):\n",
    "    if pd.notna(text):  # check if text is not NaN\n",
    "        extract_scores = text.split()[0].lower()\n",
    "        return extract_scores\n",
    "    else:\n",
    "        return str('no score')  # return NaN for missing values\n",
    "    \n",
    "df['city_score'] = df['score_status'].apply(extract_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- count_qna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qna\n",
    "def extract_qna_num(text):\n",
    "  if pd.notna(text):\n",
    "    num = text.split()[-1]\n",
    "    num = num.replace('(',\"\").replace(')',\"\")\n",
    "    return int(num)\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "df['count_qna'] = df.count_qna.apply(extract_qna_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- count_reviewer_by_cat & count_reviewer_by_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_reviewer_category\n",
    "def extract_category_counts(df, column_names):\n",
    "    # Create a dictionary to store extracted values\n",
    "    extracted_values = {}\n",
    "\n",
    "    for column_name in column_names:\n",
    "        # Iterate over rows\n",
    "        for index, row in df.iterrows():\n",
    "            category_counts = {}\n",
    "\n",
    "            if pd.notna(row[column_name]):\n",
    "                # Use regular expressions to extract category counts\n",
    "                counts = re.findall(r'\\((\\d+)\\)', row[column_name])\n",
    "                categories = re.findall(r'([A-Za-z\\s]+) \\(\\d+\\)', row[column_name])\n",
    "                cat_num = re.findall(r'([A-Za-z\\s\\d+: –]+) \\(\\d+\\)', row[column_name])\n",
    "\n",
    "                # Determine whether to use 'categories' or 'cat_num'\n",
    "                cat_list = cat_num if any(char.isdigit() for char in ''.join(cat_num)) else categories\n",
    "\n",
    "                # Create a dictionary to store the counts for each category\n",
    "                category_counts = dict(zip(cat_list, map(int, counts)))\n",
    "\n",
    "                # Fill in missing categories with 0\n",
    "                for category in set(cat_list):\n",
    "                    if category not in category_counts and category.lower() != 'all':\n",
    "                        category_counts[category] = 0\n",
    "\n",
    "                # Convert values to lowercase and remove white spaces\n",
    "                category_counts = {key.lower().strip(): value for key, value in category_counts.items() if key.lower().strip() != 'all'}\n",
    "\n",
    "                # Add \"count\" to each extracted value\n",
    "                category_counts = {f'count_{key}': value for key, value in category_counts.items()}\n",
    "\n",
    "            # Update the dictionary with extracted values\n",
    "            for title, value in category_counts.items():\n",
    "                if title not in extracted_values:\n",
    "                    extracted_values[title] = [0] * len(df)\n",
    "\n",
    "                # Ensure the list has enough elements to accommodate the current index\n",
    "                while len(extracted_values[title]) <= index:\n",
    "                    extracted_values[title].append(0)\n",
    "\n",
    "                extracted_values[title][index] = value\n",
    "\n",
    "    # Add the extracted values to the DataFrame\n",
    "    for title, values in extracted_values.items():\n",
    "        # Ensure the length of the values matches the length of the DataFrame\n",
    "        values = values[:len(df)]\n",
    "        df[title] = values\n",
    "\n",
    "    return df\n",
    "\n",
    "cols_to_extract = ['count_reviewer_by_cat', 'count_reviewer_by_scores']\n",
    "df = extract_category_counts(df, cols_to_extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- count_reviewer_by_lan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_language_data(df, count_reviewer_by_lan):\n",
    "    # Read the column\n",
    "    language_data = df[count_reviewer_by_lan]\n",
    "\n",
    "    # Initialize new columns\n",
    "    df['lan_eng_proportion'] = 0.0\n",
    "    df['lan_malay_proportion'] = 0.0\n",
    "    df['lan_others_proportion'] = 0.0\n",
    "\n",
    "    # Lists to store proportions for each row\n",
    "    eng_proportions = []\n",
    "    malay_proportions = []\n",
    "    others_proportions = []\n",
    "\n",
    "    # Preprocess\n",
    "    for data in language_data:\n",
    "        if pd.isna(data):\n",
    "            eng_proportions.append(0)\n",
    "            malay_proportions.append(0)\n",
    "            others_proportions.append(0)\n",
    "            continue  # Skip if the value is null\n",
    "\n",
    "        languages = re.findall(r'(\\w+) \\((\\d+)\\)', data)\n",
    "        total_count = int(re.search(r'All \\((\\d+)\\)', data).group(1))\n",
    "\n",
    "        eng_count, malay_count, others_count = 0, 0, 0\n",
    "\n",
    "        for language, count in languages:\n",
    "            proportion = int(count) / total_count * 100\n",
    "\n",
    "            if language == 'English':\n",
    "                eng_count = int(count)\n",
    "            elif language == 'Malay':\n",
    "                malay_count = int(count)\n",
    "            else:\n",
    "                others_count += int(count)\n",
    "\n",
    "        eng_proportions.append(eng_count / total_count * 100)\n",
    "        malay_proportions.append(malay_count / total_count * 100)\n",
    "        others_proportions.append((100 - (eng_count + malay_count) / total_count * 100) if total_count != 0 else 0)\n",
    "\n",
    "    # Update DataFrame with calculated proportions\n",
    "    df['lan_eng_proportion'] = eng_proportions\n",
    "    df['lan_malay_proportion'] = malay_proportions\n",
    "    df['lan_others_proportion'] = others_proportions\n",
    "\n",
    "    # Replace NaN values in the specified columns with 0\n",
    "    df.loc[df[count_reviewer_by_lan].isna(), ['lan_eng_proportion', 'lan_malay_proportion', 'lan_others_proportion']] = 0\n",
    "\n",
    "    return df\n",
    "\n",
    "df = process_language_data(df, 'count_reviewer_by_lan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 Host<a id=\"6\"></a> [![Static Badge](https://img.shields.io/badge/Back_to_Table_of_Contents-orange?style=flat&logo=jupyter&logoColor=white)](#main)\n",
    "\n",
    "- host_count_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_count_reviews\n",
    "def extract_review_and_properties(text):\n",
    "    if pd.notna(text):\n",
    "        review = text.split()[2]\n",
    "        review = review.replace(',', '')\n",
    "        prop = text.split()[-2]\n",
    "        prop = prop.replace(',', '')\n",
    "        return int(review), int(prop)\n",
    "    else:\n",
    "        return 0, 0\n",
    "    \n",
    "df[['host_count_reviews', 'host_properties']] = df['host_count_reviews'].apply(lambda x: pd.Series(extract_review_and_properties(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5 Surrounding<a id=\"7\"></a> [![Static Badge](https://img.shields.io/badge/Back_to_Table_of_Contents-orange?style=flat&logo=jupyter&logoColor=white)](#main)\n",
    "\n",
    "- landmarks, topattractions, publictransport, closestairports & restaurantscafes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full function\n",
    "def process_distance_collected(distance_str):\n",
    "    if pd.isna(distance_str):  # Check if the input is NaN\n",
    "        return 0\n",
    "\n",
    "    # Function to convert meters to kilometers\n",
    "    def convert_to_km(distance_str):\n",
    "        distances = re.findall(r'(\\d+)\\s*m', distance_str)\n",
    "        if not distances:\n",
    "            return \"\"  # Return an empty string if no distances are found\n",
    "        distances_km = [str(float(d) / 1000) for d in distances]  # Convert to kilometers and create a list of strings\n",
    "        return \", \".join(distances_km)  # Join the distances together with a separator\n",
    "\n",
    "    # Function to extract distances in kilometers\n",
    "    def km_extracter(distance_str):\n",
    "        distances = re.findall(r'(\\d+\\.\\d+|\\d+)\\s*km', distance_str)\n",
    "        if not distances:\n",
    "            return \"\"  # Return an empty string if no distances are found\n",
    "        return \", \".join(distances)\n",
    "\n",
    "    # Function to calculate median distance\n",
    "    def calculate_median(combined_distances_str):\n",
    "        if not combined_distances_str:\n",
    "            return None\n",
    "        combined_distances = list(map(float, combined_distances_str.split(', ')))\n",
    "        combined_distances.sort()\n",
    "        median_index = len(combined_distances) // 2\n",
    "        return combined_distances[median_index]\n",
    "\n",
    "    # Apply the functions sequentially\n",
    "    m_to_km = convert_to_km(distance_str)\n",
    "    km = km_extracter(distance_str)\n",
    "\n",
    "    # Combine m_to_km and km into a single string\n",
    "    combined_distances_str = \", \".join(filter(None, [m_to_km, km]))\n",
    "\n",
    "    # Calculate median\n",
    "    median_distance = calculate_median(combined_distances_str)\n",
    "\n",
    "    return median_distance\n",
    "\n",
    "df['average_all_landmarks_distances'] = df['all_landmarks_distances'].apply(process_distance_collected)\n",
    "df['average_all_topattractions_distances'] = df['all_topattractions_distances'].apply(process_distance_collected)\n",
    "df['average_all_publictransports_distances'] = df['all_publictransports_distances'].apply(process_distance_collected)\n",
    "df['average_all_closestairports_distances'] = df['all_closestairports_distances'].apply(process_distance_collected)\n",
    "df['average_all_restaurantscafes_distances'] = df['all_restaurantscafes_distances'].apply(process_distance_collected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.6 Facilities<a id=\"8\"></a> [![Static Badge](https://img.shields.io/badge/Back_to_Table_of_Contents-orange?style=flat&logo=jupyter&logoColor=white)](#main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_new_cats_cols(df, key_values_dict):\n",
    "    new_columns = {key: [0]*len(df) for key in key_values_dict.keys()}\n",
    "    for key, values in new_columns.items():\n",
    "        df[key] = values\n",
    "    return df\n",
    "\n",
    "def update_value_cat_cols(df, col_name, key_values_dict):\n",
    "    for idx, row in df.iterrows():\n",
    "        if pd.isnull(row[col_name]):\n",
    "            continue\n",
    "\n",
    "        steps = set()  # To keep track of unique steps encountered\n",
    "        for step in [step.lower().replace(' ', '_') for step in row[col_name].split(', ')]:\n",
    "            if step not in steps:  # Check if step is encountered for the first time\n",
    "                for key, values in key_values_dict.items():\n",
    "                    if step in values:\n",
    "                        df.at[idx, key] += 1\n",
    "                steps.add(step)  # Add the step to the set of encountered steps\n",
    "    return df\n",
    "\n",
    "def update_key_cat_cols(df, col_name, key_values_dict, key_name):\n",
    "# Initialize count for the specified key if not already present\n",
    "    if key_name not in df.columns:\n",
    "        df[key_name] = 0\n",
    "\n",
    "    # Update count based on key_name\n",
    "    for idx, row in df.iterrows():\n",
    "        if pd.notnull(row[col_name]):\n",
    "            steps = [step.lower().replace(' ', '_') for step in row[col_name].split(', ')]\n",
    "            if key_name in steps:\n",
    "                df.at[idx, key_name] += 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: Booking.com\n",
    "facilities = {\n",
    "    'accessibility': [\n",
    "      'auditory_guidance',\n",
    "      'emergency_cord_in_bathroom',\n",
    "      'entire_unit_located_on_ground_floor',\n",
    "      'entire_unit_wheelchair_accessible',\n",
    "      'hearing_accessible',\n",
    "      'upper_floors_accessible_by_elevator',\n",
    "      'upper_floors_accessible_by_stairs_only'\n",
    "    ],\n",
    "    'activities': [\n",
    "      'aerobics',\n",
    "      'archery',\n",
    "      'badminton_equipment',\n",
    "      'beach',\n",
    "      'bike_tours',\n",
    "      'billiards',\n",
    "      'bingo',\n",
    "      'bowling',\n",
    "      'canoeing',\n",
    "      'cooking_class',\n",
    "      'cycling',\n",
    "      'darts',\n",
    "      'diving',\n",
    "      'fishing',\n",
    "      'golf_course_(within_3_km)',\n",
    "      'happy_hour',\n",
    "      'hiking',\n",
    "      'horse_riding',\n",
    "      \"kids'_club\",\n",
    "      'mini_golf',\n",
    "      'movie_nights',\n",
    "      'pub_crawls',\n",
    "      'ski-to-door_access',\n",
    "      'ski_equipment_hire_on_site',\n",
    "      'ski_pass_vendor',\n",
    "      'ski_school',\n",
    "      'ski_storage',\n",
    "      'skiing',\n",
    "      'snorkelling',\n",
    "      'squash',\n",
    "      'table_tennis',\n",
    "      'temporary_art_galleries',\n",
    "      'tennis_court',\n",
    "      'tennis_equipment',\n",
    "      'themed_dinner_nights',\n",
    "      'tour_or_class_about_local_culture',\n",
    "      'walking_tours',\n",
    "      'water_park',\n",
    "      'water_sport_facilities_on_site',\n",
    "      'windsurfing'\n",
    "    ],\n",
    "    'bathroom': [\n",
    "      'additional_bathroom',\n",
    "      'additional_toilet',\n",
    "      'bath',\n",
    "      'bath_or_shower',\n",
    "      'bathrobe',\n",
    "      'bidet',\n",
    "      'free_toiletries',\n",
    "      'hairdryer',\n",
    "      'private_bathroom',\n",
    "      'shared_toilet',\n",
    "      'shower',\n",
    "      'slippers',\n",
    "      'toilet',\n",
    "      'toilet_paper',\n",
    "      'towels',\n",
    "      'towels/sheets_(extra_fee)'\n",
    "    ],\n",
    "    'bedroom':[\n",
    "      'alarm_clock',\n",
    "      'dressing_room',\n",
    "      'extra_long_beds_(>_2_metres)',\n",
    "      'linen',\n",
    "      'wardrobe_or_closet'\n",
    "    ],\n",
    "    'building_characteristics': [\n",
    "      'detached',\n",
    "      'private_apartment_in_building',\n",
    "      'semi-detached'\n",
    "    ],\n",
    "    'business_facilities': [\n",
    "      'business_centre',\n",
    "      'fax',\n",
    "      'fax/photocopying',\n",
    "      'meeting/banquet_facilities'\n",
    "    ],\n",
    "    'cleaning_services': [\n",
    "      'daily_housekeeping',\n",
    "      'dry_cleaning',\n",
    "      'ironing_service',\n",
    "      'laundry',\n",
    "      'trouser_press'\n",
    "      ],\n",
    "    'common_areas': [\n",
    "      'chapel/shrine',\n",
    "      'games_room',\n",
    "      'shared_lounge/tv_area'\n",
    "    ],\n",
    "    'entertainment_and_family_services': [\n",
    "      'baby_safety_gates',\n",
    "      'babysitting/child_services',\n",
    "      'board_games/puzzles',\n",
    "      'books',\n",
    "      'casino',\n",
    "      'child_safety_socket_covers',\n",
    "      \"children's_playground\",\n",
    "      'dvds',\n",
    "      'entertainment_staff',\n",
    "      'evening_entertainment',\n",
    "      'indoor_play_area',\n",
    "      'karaoke',\n",
    "      \"kids'_outdoor_play_equipment\",\n",
    "      'live_music/performance',\n",
    "      'live_sport_events_(broadcast)',\n",
    "      'nightclub/dj',\n",
    "      'or_music_for_children',\n",
    "      'stand-up_comedy'\n",
    "    ],\n",
    "    'food_&_drink': [\n",
    "      'bar',\n",
    "      'breakfast_in_the_room',\n",
    "      'coffee_house_on_site',\n",
    "      'fruits',\n",
    "      'grocery_deliveries',\n",
    "      'kid-friendly_buffet',\n",
    "      'kid_meals',\n",
    "      'minibar',\n",
    "      'packed_lunches',\n",
    "      'restaurant',\n",
    "      'room_service',\n",
    "      'snack_bar',\n",
    "      'special_diet_menus_(on_request)',\n",
    "      'tea/coffee_maker',\n",
    "      'vending_machine_(drinks)',\n",
    "      'vending_machine_(snacks)',\n",
    "      'wine/champagne'\n",
    "    ],\n",
    "    'internet': [\n",
    "      'internet_available'\n",
    "    ],\n",
    "    'kitchen': [\n",
    "      \"children's_high_chair\",\n",
    "      'cleaning_products',\n",
    "      'coffee_machine',\n",
    "      'dining_table',\n",
    "      'dishwasher',\n",
    "      'electric_kettle',\n",
    "      'kitchen',\n",
    "      'kitchenette',\n",
    "      'kitchenware',\n",
    "      'microwave',\n",
    "      'oven',\n",
    "      'refrigerator',\n",
    "      'shared_kitchen',\n",
    "      'stovetop',\n",
    "      'toaster',\n",
    "      'tumble_dryer',\n",
    "      'washing_machine'\n",
    "    ],\n",
    "    'languages_spoken': [\n",
    "      'afrikaans',\n",
    "      'arabic',\n",
    "      'bengali',\n",
    "      'bulgarian',\n",
    "      'burmese',\n",
    "      'cantonese',\n",
    "      'chinese',\n",
    "      'czech',\n",
    "      'dutch',\n",
    "      'english',\n",
    "      'farsi',\n",
    "      'filipino',\n",
    "      'french',\n",
    "      'georgian',\n",
    "      'german',\n",
    "      'gujarati',\n",
    "      'hausa',\n",
    "      'hindi',\n",
    "      'indonesian',\n",
    "      'irish',\n",
    "      'italian',\n",
    "      'japanese',\n",
    "      'javanese',\n",
    "      'khmer',\n",
    "      'korean',\n",
    "      'lao',\n",
    "      'macedonian',\n",
    "      'malay',\n",
    "      'malayalam',\n",
    "      'maltese',\n",
    "      'mandarin',\n",
    "      'mongolian',\n",
    "      'norwegian',\n",
    "      'polish',\n",
    "      'portuguese',\n",
    "      'punjabi',\n",
    "      'romanian',\n",
    "      'russian',\n",
    "      'spanish',\n",
    "      'swedish',\n",
    "      'tamil',\n",
    "      'telugu',\n",
    "      'thai',\n",
    "      'turkish',\n",
    "      'ukrainian',\n",
    "      'urdu',\n",
    "      'vietnamese'\n",
    "    ],\n",
    "    'living_area': [\n",
    "      'desk',\n",
    "      'dining_area',\n",
    "      'fireplace',\n",
    "      'seating_area',\n",
    "      'sofa'\n",
    "    ],\n",
    "    'media_&_technology': [\n",
    "      'blu-ray_player',\n",
    "      'cable_channels',\n",
    "      'cd_player',\n",
    "      'computer',\n",
    "      'dvd_player',\n",
    "      'flat-screen_tv',\n",
    "      'game_console',\n",
    "      'game_console_–_nintendo_wii',\n",
    "      'game_console_–_ps2',\n",
    "      'game_console_–_ps3',\n",
    "      'game_console_–_xbox_360',\n",
    "      'ipad',\n",
    "      'ipod_dock',\n",
    "      'laptop',\n",
    "      'laptop_safe',\n",
    "      'pay-per-view_channels',\n",
    "      'radio',\n",
    "      'satellite_channels',\n",
    "      'streaming_service_(like_netflix)',\n",
    "      'telephone',\n",
    "      'tv',\n",
    "      'video',\n",
    "      'video_games'\n",
    "    ],\n",
    "    'miscellaneous': [\n",
    "      'air_conditioning',\n",
    "      'allergy-free_room',\n",
    "      'designated_smoking_area',\n",
    "      'facilities_for_disabled_guests',\n",
    "      'family_rooms',\n",
    "      'heating',\n",
    "      'higher_level_toilet',\n",
    "      'lift',\n",
    "      'lower_bathroom_sink',\n",
    "      'non-smoking_rooms',\n",
    "      'non-smoking_throughout',\n",
    "      'pet_basket',\n",
    "      'pet_bowls',\n",
    "      'soundproof_rooms',\n",
    "      'strollers',\n",
    "      'toilet_with_grab_rails',\n",
    "      'visual_aids:_braille',\n",
    "      'visual_aids:_tactile_signs',\n",
    "      'wheelchair_accessible'\n",
    "    ],\n",
    "    'outdoor_&_view': [\n",
    "      'city_view',\n",
    "      'garden_view',\n",
    "      'inner_courtyard_view',\n",
    "      'lake_view',\n",
    "      'landmark_view',\n",
    "      'mountain_view',\n",
    "      'pool_view',\n",
    "      'river_view',\n",
    "      'sea_view',\n",
    "      'view'\n",
    "    ],\n",
    "    'outdoors': [\n",
    "      'balcony',\n",
    "      'barbecue',\n",
    "      'bbq_facilities',\n",
    "      'beachfront',\n",
    "      'garden',\n",
    "      'outdoor_dining_area',\n",
    "      'outdoor_fireplace',\n",
    "      'outdoor_furniture',\n",
    "      'patio',\n",
    "      'picnic_area',\n",
    "      'private_beach_area',\n",
    "      'private_pool',\n",
    "      'solarium',\n",
    "      'sun_terrace',\n",
    "      'terrace'\n",
    "    ],\n",
    "    'parking': [\n",
    "      'accessible_parking',\n",
    "      'electric_vehicle_charging_station',\n",
    "      'parking_garage',\n",
    "      'street_parking',\n",
    "      'valet_parking'\n",
    "    ],\n",
    "    'pets': [\n",
    "      'pets_allowed'\n",
    "    ],\n",
    "    'reception_services': [\n",
    "      '24-hour_front_desk',\n",
    "      'atm/cash_machine_on_site',\n",
    "      'concierge_service',\n",
    "      'currency_exchange',\n",
    "      'express_check-in/check-out',\n",
    "      'invoice_provided',\n",
    "      'lockers',\n",
    "      'luggage_storage',\n",
    "      'private_check-in/check-out',\n",
    "      'tour_desk'\n",
    "    ],\n",
    "    'room_amenities': [\n",
    "      'carpeted',\n",
    "      'clothes_rack',\n",
    "      'drying_rack_for_clothing',\n",
    "      'electric_blankets',\n",
    "      'fan',\n",
    "      'fold-up_bed',\n",
    "      'hardwood_or_parquet_floors',\n",
    "      'hot_tub',\n",
    "      'hypoallergenic',\n",
    "      'interconnected_room(s)_available',\n",
    "      'iron',\n",
    "      'ironing_facilities',\n",
    "      'mosquito_net',\n",
    "      'pants_press',\n",
    "      'private_entrance',\n",
    "      'socket_near_the_bed',\n",
    "      'sofa_bed',\n",
    "      'soundproofing',\n",
    "      'tile/marble_floor'\n",
    "    ],\n",
    "    'safety_&_security': [\n",
    "      '24-hour_security',\n",
    "      'carbon_monoxide_detector',\n",
    "      'cctv_in_common_areas',\n",
    "      'cctv_outside_property',\n",
    "      'fire_extinguishers',\n",
    "      'key_access',\n",
    "      'key_card_access',\n",
    "      'safety_deposit_box',\n",
    "      'security_alarm',\n",
    "      'smoke_alarms'\n",
    "    ],\n",
    "    'services_&_extras': [\n",
    "      'executive_lounge_access',\n",
    "      'wake-up_service',\n",
    "      'wake_up_service/alarm_clock'\n",
    "    ],\n",
    "    'shops': [\n",
    "      'barber/beauty_shop',\n",
    "      'minimarket_on_site'\n",
    "    ],\n",
    "    'swimming_pool': [\n",
    "      'adult_only',\n",
    "      'all_ages_welcome',\n",
    "      'fence_around_pool',\n",
    "      'heated_pool',\n",
    "      'hot_spring_bath',\n",
    "      'infinity_pool',\n",
    "      'open_all_year',\n",
    "      'opening_times',\n",
    "      'plunge_pool',\n",
    "      'pool/beach_towels',\n",
    "      'pool_bar',\n",
    "      'pool_cover',\n",
    "      'pool_is_on_rooftop',\n",
    "      'pool_with_view',\n",
    "      'salt-water_pool',\n",
    "      'seasonal',\n",
    "      'shallow_end',\n",
    "      'suitable_for_kids',\n",
    "      'sun_loungers_or_beach_chairs',\n",
    "      'sun_umbrellas',\n",
    "      'swimming_pool_toys',\n",
    "      'water_slide'\n",
    "    ],\n",
    "    'transport': [\n",
    "      'airport_shuttle',\n",
    "      'bicycle_rental',\n",
    "      'car_hire',\n",
    "      'public_transport_tickets',\n",
    "      'shuttle_service'\n",
    "    ],\n",
    "    'wellness': [\n",
    "      'back_massage',\n",
    "      'beauty_services',\n",
    "      'body_scrub',\n",
    "      'body_treatments',\n",
    "      'body_wrap',\n",
    "      'couples_massage',\n",
    "      'facial_treatments',\n",
    "      'fitness',\n",
    "      'fitness/spa_locker_rooms',\n",
    "      'fitness_centre',\n",
    "      'fitness_classes',\n",
    "      'foot_bath',\n",
    "      'foot_massage',\n",
    "      'full_body_massage',\n",
    "      'hair_colouring',\n",
    "      'hair_cut',\n",
    "      'hair_styling',\n",
    "      'hair_treatments',\n",
    "      'hammam',\n",
    "      'hand_massage',\n",
    "      'head_massage',\n",
    "      'hot_tub/jacuzzi',\n",
    "      'kids\\'_pool',\n",
    "      'light_therapy',\n",
    "      'make_up_services',\n",
    "      'manicure',\n",
    "      'massage',\n",
    "      'massage_chair',\n",
    "      'neck_massage',\n",
    "      'open-air_bath',\n",
    "      'pedicure',\n",
    "      'personal_trainer',\n",
    "      'public_bath',\n",
    "      'sauna',\n",
    "      'spa/wellness_packages',\n",
    "      'spa_and_wellness_centre',\n",
    "      'spa_bath',\n",
    "      'spa_facilities',\n",
    "      'spa_lounge/relaxation_area',\n",
    "      'steam_room',\n",
    "      'sun_loungers_or_beach_chairs',\n",
    "      'waxing_services',\n",
    "      'yoga_classes'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = init_new_cats_cols(df, facilities)\n",
    "df = update_value_cat_cols(df, 'sub_facilities', facilities)\n",
    "df = update_key_cat_cols(df, 'facilities', facilities, 'pets')\n",
    "df = update_key_cat_cols(df, 'facilities', facilities, 'parking')\n",
    "df = update_key_cat_cols(df, 'facilities', facilities, 'internet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.7 Sustainability<a id=\"9\"></a> [![Static Badge](https://img.shields.io/badge/Back_to_Table_of_Contents-orange?style=flat&logo=jupyter&logoColor=white)](#main)\n",
    "\n",
    "- sustainable_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sustainable_label(level):\n",
    "    if level == 0:\n",
    "        return 'non-travel sustainable'\n",
    "    else:\n",
    "        return 'travel sustainable'\n",
    "    \n",
    "df['sustainable_label'] = df['travel_sustainable_level'].apply(lambda x: create_sustainable_label(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sustainable impact category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: Booking.com\n",
    "impact_categories = {\n",
    "    'energy_and_greenhouse_gases': [\n",
    "        \"most_lighting_throughout_property_uses_energy-efficient_led_bulbs\",\n",
    "        \"all_windows_are_double-glazed\",\n",
    "        \"vegetarian_menu_options_offered\",\n",
    "        \"vegan_menu_options_offered\",\n",
    "        \"key_card_or_motion-controlled_electricity\",\n",
    "        \"100%_renewable_electricity_used_throughout\",\n",
    "        \"the_property_makes_efforts_to_reduce_their_food_wastage\",\n",
    "        \"most_food_provided_at_the_property_is_locally_sourced\",\n",
    "        \"electric_car_charging_station\"\n",
    "    ],\n",
    "    'waste': [\n",
    "        \"single-use_plastic_miniature_shampoo_conditioner_and_body_wash_bottles_not_used\",\n",
    "        \"single-use_plastic_water_bottles_not_used\",\n",
    "        \"water_cooler/dispenser\",\n",
    "        \"single-use_plastic_beverage_bottles_not_used\",\n",
    "        \"single-use_plastic_cutlery/plates_not_used\",\n",
    "        \"single-use_plastic_cups_not_used\",\n",
    "        \"single-use_plastic_straws_not_used\",\n",
    "        \"single-use_plastic_stirrers_not_used\",\n",
    "        \"recycling_bins_available_to_guests_and_waste_is_recycled\"\n",
    "    ],\n",
    "    'destination_and_community': [\n",
    "        \"local_artists_are_offered_a_platform_to_display_their_talents\",\n",
    "        \"tours_and_activities_organised_by_local_guides_and_businesses_offered\",\n",
    "        \"invests_a_percentage_of_revenue_back_into_community_projects_or_sustainability_projects\",\n",
    "        \"provides_guests_with_information_regarding_local_ecosystems,_heritage_and_culture,_as_well_as_visitor_etiquette\"\n",
    "    ],\n",
    "    'water': [\n",
    "        \"water-efficient_toilets\",\n",
    "        \"water-efficient_showers\",\n",
    "        \"option_to_reuse_towels\",\n",
    "        \"option_to_opt-out_of_daily_room_cleaning\"\n",
    "    ],\n",
    "    'nature': [\n",
    "        \"wild_(non-domesticated)_animals_are_not_displayed/interacted_with_while_captive_on_the_property_or_harvested,_consumed,_or_sold.\",\n",
    "        \"offsets_a_portion_of_their_carbon_footprint\",\n",
    "        \"most_food_provided_is_organic\",\n",
    "        \"green_spaces_such_as_gardens/rooftop_gardens_on_the_property\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = init_new_cats_cols(df, impact_categories)\n",
    "df = update_value_cat_cols(df, 'sustainable_steps_taken', impact_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Finalising Dataset<a id=\"10\"></a> [![Static Badge](https://img.shields.io/badge/Back_to_Table_of_Contents-orange?style=flat&logo=jupyter&logoColor=white)](#main)\n",
    "\n",
    "2.4.1 Dropping the original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15263, 84)\n"
     ]
    }
   ],
   "source": [
    "# dropping the original features\n",
    "cols_to_drop = [\n",
    "  'name',\n",
    "  'address',\n",
    "  'coordinate',\n",
    "  'description',\n",
    "  'prices_range',\n",
    "  'review_titles',\n",
    "  'review_overall_scores',\n",
    "  'score_status',\n",
    "  'count_reviewer_by_cat',\n",
    "  'count_reviewer_by_scores',\n",
    "  'count_reviewer_by_lan',\n",
    "  'all_landmarks_distances',\n",
    "  'all_topattractions_distances',\n",
    "  'all_publictransports_distances',\n",
    "  'all_closestairports_distances',\n",
    "  'all_restaurantscafes_distances',\n",
    "  'count_facilities',\n",
    "  'count_sub_facilities',\n",
    "  'facilities',\n",
    "  'sub_facilities',\n",
    "  'count_sustainable_steps_title',\n",
    "  'sustainable_steps_title',\n",
    "  'count_sustainable_steps_taken',\n",
    "  'sustainable_steps_taken',\n",
    "  'extracted_postcode',\n",
    "  'review_0'\n",
    "  ]\n",
    "\n",
    "df = df.drop(cols_to_drop, axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.2 Move the target feature to the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the target to the end\n",
    "# Column to move to the last position\n",
    "column_to_move = 'sustainable_label'\n",
    "\n",
    "# Reorder the columns\n",
    "new_columns = [col for col in df.columns if col != column_to_move] + [column_to_move]\n",
    "df = df[new_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.3 Final check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame does not contain null or NaN values\n"
     ]
    }
   ],
   "source": [
    "# check every single feature if there any existence of null or NaN values\n",
    "null_columns = df.columns[df.isnull().any(axis=0)]\n",
    "if len(null_columns) > 0:\n",
    "    print(\"DataFrame contains null or NaN values in the following columns:\")\n",
    "    for column in null_columns:\n",
    "        print(column)\n",
    "else:\n",
    "    print(\"DataFrame does not contain null or NaN values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.4 Saving the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './../data/processed/processed_data.csv'\n",
    "df.to_csv(save_dir, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Process Dataset for Modeling<a id=\"11\"></a> [![Static Badge](https://img.shields.io/badge/Back_to_Table_of_Contents-orange?style=flat&logo=jupyter&logoColor=white)](#main)\n",
    "\n",
    "2.5.1 Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully processed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def process_dataset(df):\n",
    "    # Define the mapping inside the function\n",
    "    mapping = {\n",
    "        'travel_sustainable_level': {\n",
    "            0: 0,\n",
    "            'Travel Sustainable Level 1': 1,\n",
    "            'Travel Sustainable Level 2': 2,\n",
    "            'Travel Sustainable Level 3': 3,\n",
    "            'Travel Sustainable Level 3+': 4\n",
    "        },\n",
    "        'city_score': {\n",
    "            'no score': 0,\n",
    "            'low': 1,\n",
    "            'high': 2\n",
    "        },\n",
    "        'sustainable_label': {\n",
    "            'non-travel sustainable': 0,\n",
    "            'travel sustainable': 1\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Normalize and encode 'city' column\n",
    "    city_frequencies = df['city'].value_counts(normalize=True)\n",
    "    city_encoding = df['city'].map(city_frequencies)\n",
    "    df['city'] = city_encoding\n",
    "\n",
    "    # Normalize and encode 'state' column\n",
    "    state_frequencies = df['state'].value_counts(normalize=True)\n",
    "    state_encoding = df['state'].map(state_frequencies)\n",
    "    df['state'] = state_encoding\n",
    "\n",
    "    # Apply mappings to the specified features\n",
    "    for feature, map_dict in mapping.items():\n",
    "        df[feature] = df[feature].map(lambda x: map_dict.get(x, x))  # Preserve original value if not found in mapping\n",
    "\n",
    "    # Ensure 'travel_sustainable_level' is of type int\n",
    "    df['travel_sustainable_level'] = df['travel_sustainable_level'].astype(int)\n",
    "\n",
    "    # print process completed\n",
    "    print('Dataset successfully processed!\\n')\n",
    "\n",
    "    return df\n",
    "\n",
    "processed_df = process_dataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5.2 Handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize_columns(df, columns, limits=(0.05, 0.05)):\n",
    "    \"\"\"\n",
    "    Apply Winsorizing to specific columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): DataFrame containing the columns to be winsorized.\n",
    "        columns (list of str): Names of the columns to be winsorized.\n",
    "        limits (tuple of float): Lower and upper limits of the winsorization.\n",
    "                                  Values outside the limits will be replaced.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with winsorized values for specified columns.\n",
    "    \"\"\"\n",
    "    winsorized_df = df.copy()\n",
    "    for column in columns:\n",
    "        winsorized_df[column] = mstats.winsorize(df[column], limits=limits)\n",
    "    return winsorized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_outliers = [\n",
    "    \"count_room_types\",\n",
    "    \"count_reviews\",\n",
    "    \"host_score_review\",\n",
    "    \"host_count_reviews\",\n",
    "    \"count_landmarks\",\n",
    "    \"count_closestairports\",\n",
    "    \"count_restaurantscafes\",\n",
    "    \"average_price\",\n",
    "    \"count_families\",\n",
    "    \"count_couples\",\n",
    "    \"count_groups of friends\",\n",
    "    \"count_solo travellers\",\n",
    "    \"count_business travellers\",\n",
    "    \"count_superb: 9+\",\n",
    "    \"count_good: 7 – 9\",\n",
    "    \"count_passable: 5 – 7\",\n",
    "    \"count_poor: 3 – 5\",\n",
    "    \"count_very poor: 1 – 3\",\n",
    "    \"lan_malay_proportion\",\n",
    "    \"lan_others_proportion\",\n",
    "    \"host_properties\",\n",
    "    \"average_all_landmarks_distances\",\n",
    "    \"average_all_topattractions_distances\",\n",
    "    \"average_all_closestairports_distances\",\n",
    "    \"average_all_restaurantscafes_distances\",\n",
    "    \"accessibility\",\n",
    "    \"activities\",\n",
    "    \"bedroom\",\n",
    "    \"building_characteristics\",\n",
    "    \"business_facilities\",\n",
    "    \"cleaning_services\",\n",
    "    \"common_areas\",\n",
    "    \"entertainment_and_family_services\",\n",
    "    \"food_&_drink\",\n",
    "    \"kitchen\",\n",
    "    \"languages_spoken\",\n",
    "    \"media_&_technology\",\n",
    "    \"miscellaneous\",\n",
    "    \"outdoor_&_view\",\n",
    "    \"outdoors\",\n",
    "    \"parking\",\n",
    "    \"reception_services\",\n",
    "    \"room_amenities\",\n",
    "    \"services_&_extras\",\n",
    "    \"swimming_pool\",\n",
    "    \"transport\",\n",
    "    \"wellness\",\n",
    "    \"energy_and_greenhouse_gases\",\n",
    "    \"destination_and_community\",\n",
    "    \"nature\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "winsorized_df = winsorize_columns(processed_df, cols_with_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5.3 Saving the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_dir = './../data/modeling/modeling_data.csv'\n",
    "winsorized_df.to_csv(save_model_dir, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
